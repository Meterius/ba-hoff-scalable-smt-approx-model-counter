from hash_generation_finder.\
    uniform_pairwise_independent_hash_sets.\
    alpha_data_set_bit_domain_based_analysis.upi_sets_n2k3_exec import upi_sets_n2k3
from hash_generation_finder.utility import is_hash_set_dual_extension, is_hash_set_symmetric, \
    get_hash_set_dual_extension_via_paired_inverses, convert_hash_set_to_tuple_representation, are_hash_sets_equal, \
    invert_hash_set, get_hash_set_identifier, get_hash_set_permutation
from hash_generation_finder.upi_hashing import get_paper_xor_hash_set
from hash_generation_finder.old_code.hashing import is_pairwise_independent_hash_set
from itertools import combinations, product
from z3 import *
from math import *
import numpy as np

# Runs some filtering on the already generated upi hashing generation

if __name__ == "__main__":
    """
    # Quite a lot of hash sets in n3k4 are dual extension of some hash set in n2k3
    for (i, H1), (j, H2) in product(enumerate(upi_sets_n2k3), enumerate(upi_sets_n3k4)):
        if is_hash_set_dual_extension(H1, H2):
            print(i + 1, j + 1)
    """

    """
    def list_equivalences_of_hash_sets(
        HS,
        equivalence,
    ):
        QUEUE = set(range(len(HS)))
        no_space = int(ceil(log10(len(HS) + 1)) + 1)

        while len(QUEUE) > 0:
            i = QUEUE.pop()

            print(f"    {str(i + 1).ljust(no_space)}({get_hash_set_identifier(HS[i])})")

            EQ = [i]

            INSP = QUEUE.copy()

            while len(INSP) > 0:
                j = INSP.pop()
                op = equivalence(HS[i], HS[j])

                if op is not False and op is not None:
                    print(f"    {str(j + 1).ljust(no_space)}({get_hash_set_identifier(HS[j])})")
                    print(f"    {' ' * no_space}{op}")
                    QUEUE.remove(j)
                    EQ.append(j)

            print("")

    list_equivalences_of_hash_sets(upi_sets_n2k3, get_hash_set_permutation)
    """

    """
    def list_relation_of_hash_sets(
        HS,
        relation,
        is_symmetric,
        is_reflexive,
    ):
        no_space = int(ceil(log10(len(HS) + 1)) + 1)

        for ((i1, H1), (i2, H2)) in product(enumerate(HS), repeat=2):
            if (not is_symmetric or i1 <= i2) and (not is_reflexive or i1 != i2) and relation(H1, H2):
                print(f"    {str(i1 + 1).ljust(no_space)}({get_hash_set_identifier(H1)})     "
                      f"{str(i2 + 1).ljust(no_space)}({get_hash_set_identifier(H2)})")
    """

    """
    # Lists hash sets that are inverses of each other
    list_relation_of_hash_sets(
        upi_sets_n2k3, 
        lambda x, y: np.array_equal(invert_hash_set(x), y), 
        True,
        False,
    )
    """

    """
    for (i, H1) in enumerate(upi_sets_n3k4):
        if is_hash_set_symmetric(H1):
            print(i + 1)
    """

    """
    # Generating a dual extension using two hash sets seems to always generate a
    # new pairwise independent hash set even when generating it from one hash set and using it twice
    
    for (i, H1), (j, H2) in product(enumerate(upi_sets_n2k3), enumerate(upi_sets_n2k3)):
        H = get_hash_set_dual_extension_via_paired_inverses(H1, H2)
        HC = convert_hash_set_to_tuple_representation(H)

        if is_pairwise_independent_hash_set(len(HC[0]), HC):
            print("-----------------------------")
            print("Using H1 as")
            for h in convert_hash_set_to_tuple_representation(H1): print(h)
            print("Using H2 as")
            for h in convert_hash_set_to_tuple_representation(H2): print(h)
            print("Generates UPI")
            for h in HC: print(h)
            print(i + 1, j + 1)
    """

    """
    # But generating a dual extension using a dual extension itself wont produce a upi twice i.e.
    # it cant be used to indefinitely generate upi hash sets
    # Note: as it turns out the xor smt paper hash set is actually such a sequence i.e. it results from
    # generating the paired inverse dual extension indefinitely (i dont know yet whether there are other
    # such sequences)
    # Note: since the xor hash set can be generated by applying finite dual inverse extension to ((0,), (1,)) 
    # it is likely the only hash set that possesses that property,
    # note that this might be a deciding factor for its comparatively simple description, but also that
    # perhaps it means that for sampling the value at some point one can subtract halve the possible domain and based on
    # a single bit in the hash parameter then sample inversely or sample directly at the resulting value which can
    # be repeatedly until a directly sample-able point is reached or some other sampling method might provide a
    # integer word level description of the hash
    
    for H1, H2 in product(upi_sets_n2k3, repeat=2):
        HE1 = get_hash_set_dual_extension_via_paired_inverses(H1, H2)
        HCE1 = convert_hash_set_to_tuple_representation(HE1)
        HE2 = get_hash_set_dual_extension_via_paired_inverses(HE1, HE1)
        HCE2 = convert_hash_set_to_tuple_representation(HE2)

        if is_pairwise_independent_hash_set(len(HE2[0]), HE2):
            print("---")
            for h in HCE1: print(h)
            print("---")
            for h in HCE2: print(h)
            print("---")

            print(is_pairwise_independent_hash_set(len(HE2[0]), HE2))
    """

    """
    Identifies the SMT XOR PAPER HASH SET
    HXORC = convert_hash_set_to_tuple_representation(get_paper_xor_hash_set(2))
    for i, H in enumerate(upi_sets_n2k3):
        HC = convert_hash_set_to_tuple_representation(H)

        if HC == HXORC:
            print(i+1)
    """